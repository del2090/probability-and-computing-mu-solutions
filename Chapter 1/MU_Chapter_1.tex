\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsmath}
\usepackage{amssymb}

\title {Probability and Computing, 2nd Edition \\[2ex] \large Chapter 1 Solutions}
\author{Hahndeul Kim}
\date{January 2025}

\begin{document}

\maketitle
\newpage
\section*{1.1}
(a) Choose five coins to be the heads. $\binom{10}{5} / {2^{10}} = 63/256$.\\
(b) Choose six or more coins to be the heads. $\sum\limits_{k=6}^{10}\binom{10}{k} / {2^{10}} = 193/512$.\\
(c) For each $\textit{i}$, the probability that the two flips are the same is $1/2$. Therefore, the desired probability is $1/32$.\\
(d) $\Pr(\text{4 consecutive heads})=139/2^{10}$, ruling out duplicate cases.\\
For more than 4 consecutive heads, the counting process is straightforward.\\
$\Pr(\text{5 consecutive heads})=64/2^{10}$,
$\Pr(\text{6 consecutive heads})=28/2^{10}$,\\
$\Pr(\text{7 consecutive heads})=12/2^{10}$,
$\Pr(\text{8 consecutive heads})=5/2^{10}$,\\
$\Pr(\text{9 consecutive heads})=2/2^{10}$,
$\Pr(\text{10 consecutive heads})=1/2^{10}$,\\
In summary, the desired probability is $251/1024$.
\section*{1.2}
(a) Choose a number to be same. $6/36 = 1/6$.\\
(b) By symmetry, $1/2 \times(1-1/6) = 5/12$.\\
(c) $(1+3+5+5+3+1)/36=1/2$.\\
(d) In addition to two identical rolls, $(1,4)$ and $(4,1)$ are the cases. $8/36 = 2/9$.
\section*{1.3}
(a) The probability that no ace is included is $\binom{48}{2}/\binom{52}{2}$. Thus, the desired probability is $1-\binom{48}{2}/\binom{52}{2}$.\\
(b) Similar to (a), the desired probability is $1-\binom{48}{5}/\binom{52}{5}$.\\
(c) (Deferred Decision) Match the rank of the first card drawn. $3/51$.\\
(d) $\binom{13}{5}/\binom{52}{5}$.\\
(e) Choose a rank to be triplets and choose another rank to be doublets, then build the triplets and doublets. The desired probability is $(13\times12\times\binom{4}{3}\binom{4}{2})/\binom{52}{5}$.
\section*{1.4}
If the loser has won $\textit{k}$ games, then the total number of games played would be $\textit{n}+\textit{k}$, and the winner must have won the last game.
Thus, there are $\binom{n+k-1}{k}$ ways to choose games that the loser won.\\
Let the random variable $X$ be the number of games won by the loser. Then $\Pr(X=k)=\binom{n+k-1}{k}/2^{n+k-1}$ holds.
\section*{1.5}
(a) (1,2), (1,4), (1,9), (6,2), (6,4), (6,9), (8,2), (8,4), (8,9)\\
Alice will win with probability $5/9$.\\
(b) (2,3), (2,5), (2,7), (4,3), (4,5), (4,7), (9,3), (9,5), (9,7)\\
Alice will win with probability $5/9$.\\
(c) (3,1), (3,6), (3,8), (5,1), (5,6), (5,8), (7,1), (7,6), (7,8)\\
Alice will win with probability $5/9$.
\section*{1.6}
Let the random variable $X_n$ be the number of white balls in the bin for a fixed $n$. The claim that $\Pr(X_n=k)=1/(n-1)$ for all $k$ will be inductively proved.\\
Base Case: If n=3, $\Pr(X_3 = 1)=\Pr(X_3 = 2)=1/2$.\\
Inductive Step: Suppose that $\Pr(X_n = k) = 1/(n-1)$. Then for $n+1$, $\Pr(X_{n+1}=1)=(1/2)\times(2/3)\times\cdots\times((n-1)/n)=1/n$, $\Pr(X_{n+1}=n)=(1/2)\times(2/3)\times\cdots\times((n-1)/n)=1/n$ holds.
For $2\leq k \leq n-1$, $\Pr(X_{n+1}=k)=\Pr(X_n=k)\times((n-k)/n)+\Pr(X_n=k-1)\times((k-1)/n)=1/n$. $\blacksquare$
\section*{1.7}
(a) Inductive proof.\\
Base case: $\Pr(E_1 \cup E_2) = \Pr(E_1) + \Pr(E_2) - \Pr(E_1 \cap E_2)$. (by the axioms of probability)\\
Inductive Step: Suppose that there are $n+1$ events $E_1$, $E_2$, $\cdots$, $E_{n+1}$, and $\Pr\left(\bigcup\limits_{i=1}^k E_i\right) = \sum\limits_{i=1}^k\Pr(E_i)-\sum\limits_{i<j}\Pr(E_i \cap E_j)+\cdots+(-1)^{k+1}\Pr\left(\bigcap\limits_{i=1}^k E_i \right)$ for all $k \leq n$.
Now, $\Pr\left(\bigcup\limits_{i=1}^{n+1} E_i\right) = \Pr\left(\left(\bigcup\limits_{i=1}^n E_i\right)\bigcup E_{n+1}\right)$$=\Pr\left(\bigcup\limits_{i=1}^n E_i \right) + \Pr(E_{n+1}) - \Pr\left(\bigcup\limits_{i=1}^n (E_i \cap E_{n+1})\right)$.\\
$\Pr\left(\bigcup\limits_{i=1}^{n+1} E_i\right)$$=\Pr\left(\bigcup\limits_{i=1}^n E_i \right) + \Pr(E_{n+1}) - \Pr\left(\bigcup\limits_{i=1}^n (E_i \cap E_{n+1})\right) = \sum\limits_{i=1}^{n+1}\Pr(E_i)-\sum\limits_{i<j \leq n}\Pr(E_i \cap E_j)+\cdots+(-1)^{n+1}\Pr\left(\bigcap\limits_{i=1}^n E_i \right)$\\$-\left(\sum\limits_{i=1}^n\Pr(E_i \cap E_{n+1})-\sum\limits_{i<j<n+1}\Pr(E_i \cap E_j \cap E_{n+1})+\cdots+(-1)^{n+1}\Pr\left(\bigcap\limits_{i=1}^{n+1} E_i \right)\right)$\\
= $\sum\limits_{i=1}^{n+1}\Pr(E_i)-\sum\limits_{i<j \leq n+1}\Pr(E_i \cap E_j)+\cdots+(-1)^{n+2}\Pr\left(\bigcap\limits_{i=1}^{n+1} E_i \right)$. $\blacksquare$\\
(b), (c) Bonferroni inequalities.
\section*{1.8}
Let $D_n$ be the event that the chosen integer is divisible by $n$. Then the desired probability is $\Pr(D_4 \cup D_6 \cup D_9) = \Pr(D_4) + \Pr(D_6) + \Pr(D_9) - \Pr(D_4 \cap D_6) - \Pr(D_6 \cap D_9) - \Pr(D_4 \cap D_9) + \Pr(D_4 \cap D_6 \cap D_9) = \Pr(D_4) + \Pr(D_6) + \Pr(D_9) - \Pr(D_{12}) - \Pr(D_{18}) - \Pr(D_{36}) + \Pr(D_{36}) = 388889/1000000$.
\section*{1.9}
Let $S_i$ be the event that the $\log_2 n + k$ flips starting from the $i^{\text{th}}$ flip are consecutive heads. Then $\Pr(S_i) = (1/2)^{\log_2 n + k} = 1/2^kn$. By union bound, the desired probability $p$ is bounded as $p \leq (n-\log_2 n-k+1)/2^kn \leq 1/2^k$.
\section*{1.10}
Let A be the event that a fair coin is flipped, and B the event that a biased coin is flipped. Now, let X be the result of the flip. Then the desired probability is $\Pr(B|X=H)=\Pr(B\cap(X=H))/(\Pr(X=H|A)\Pr(A)+\Pr(X=H|B)\Pr(B))=0.5/(0.25+0.5)=2/3$.
\section*{1.11}
(a) The given probability indicates the cases where the bit is flipped even times. Flipping the bit even times is the necessary and sufficient condition to receive the correct bit.\\
(b) $\frac{1-q_1}{2} \times \frac{1+q_2}{2} + \frac{1+q_1}{2} \times \frac{1-q_2}{2} = \frac{1-q_1q_2}{2}$.\\
(c) Inductive proof.\\
Base case: when $n=1$, the probability of receiving the correct bit is $1-p$.\\
Inductive step: Suppose that the probability of receiving the correct bit after $k$ relays is $\frac{1+(1-2p)^k}{2}$. Then after $k+1$ relays, the probability is $\frac{1+(1-2p)^k}{2} \times (1-p) + \frac{1-(1-2p)^k}{2} \times p = \frac{1+(1-2p)^{k+1}}{2}$. $\blacksquare$
\section*{1.12}
Without loss of generality, assume that the contestant initially chooses the first door and Monty opens the second door. Then, $\Pr(C=1|O=2)$ and $\Pr(C=3|O=2)$ are to be compared.\\
$\Pr(C=1|O=2)=\frac{\Pr(O=2|C=1)\Pr(C=1)}{\Pr(O=2|C=1)\Pr(C=1)+\Pr(O=2|C=3)\Pr(C=3)}=\frac{1}{3}$\\
$\Pr(C=3|O=2)=\frac{\Pr(O=2|C=3)\Pr(C=3)}{\Pr(O=2|C=1)\Pr(C=1)+\Pr(O=2|C=3)\Pr(C=3)}=\frac{2}{3}$\\
Thus, the contestant should switch curtains.
\section*{1.13}
Let $D$ be the event that an individual has the disorder, and $R$ be the individual's test result.\\
$\Pr(D|R=P)=\frac{\Pr(R=P|D)\Pr(D)}{\Pr(R=P|D)\Pr(D)+\Pr(R=N|D)\Pr(D)} = \frac{0.999\times0.02}{0.999\times0.02+0.005\times0.98}\approx0.803$.
\section*{1.14}
Let $M$ be the result of the given match, $E_1$ the event that I am better, $E_2$ the event that both are equal and $E_3$ the event that the opponent is better.\\
The desired probability is $\Pr(E_3|M)=\frac{\Pr(M|E_3)\Pr(E_3)}{\Pr(M|E_1)\Pr(E_1)+\Pr(M|E_2)\Pr(E_2)+\Pr(M|E_3)\Pr(E_3)}=\frac{0.4\times0.6^3}{0.4^3\times0.6+0.5^4+0.4\times0.6^3}\approx0.461$.
\section*{1.15}
By the principle of deferred decisions, consider the situation where the last roll is left. Then, there is always a unique result of the last roll to make the final sum divisible by 6. Thus, the desired probability is $1/6$.
\section*{1.16}
(a) The desired probability is $6/6^3=1/36$.\\
(b) The desired probability is $(6\cdot5\cdot3)/6^3=5/12$.\\
(c) Under the given condition, the player will lose if he/she fails twice to roll the other die to match the other two dice. The desired probability is $1-(5/6)^2=11/36$.\\
(d) The desired probability is $\frac{1}{36}+\frac{5}{12}\times\frac{11}{36}+\frac{5}{9}\times(\frac{1}{36}+\frac{5}{12}\times\frac{1}{6}+\frac{5}{9}\times\frac{1}{36})=\frac{197}{972}$.
\section*{1.17}
If the vector $\overline{r}$ is chosen uniformly from $\{0,1,\cdots,k-1\}^n$, then\\
$\Pr(\textbf{AB}\overline{r}=\textbf{C}\overline{r})\leq 1/k$.\\
Thus, if the identity test is run p times, then the true positive probability is $1-\frac{1}{k^{p+1}+1}$.
\section*{1.18}
First, uniformly choose an integer $x$ from $\{0,\cdots,n-1\}$. Then evaluate $F(z)$ as $F(z)=F((z-x)+x)=(F(z-x)+F(x))\mod{m}$.
At the lookup table, each value $F(z-x)$ and $F(x)$ will be of the correct value with probability $4/5$.
Considering that we take modulo $m$, the output will be equal to $F(z)$ with probability at least $(4/5)^2=16/25$.\\
If the algorithm is repeated three times, then it is possible to take the majority if it exists, or otherwise simply take the first output.
For the algorithm to fail, at least two of the three outputs need to be wrong, and that occurs with probability less than $\binom{3}{2}\times(\frac{9}{25})^2\times\frac{16}{25}+\binom{3}{3}\times(\frac{9}{25})^3\approx0.295$.
Thus, the final output is correct with probability at least $0.705$.
\section*{1.19}
Let $A$ be the event that the sum of two dice rolls is $2$, and let $B$ be the event that the first roll is $2$. Then $0=\Pr(A|B)<\Pr(A)=1/36$.\\
Let $A$ be the event that a roll of a blue die is $1$, and let $B$ be the event that a roll of a red die is $1$. Then $\Pr(A|B)=\Pr(A)=1/36$.\\
Let $A$ be the event that the sum of two dice rolls is $2$, and let $B$ be the event that the first roll is $1$. Then $1/6=\Pr(A|B)>\Pr(A)=1/36$.
\section*{1.20}
The goal is to show that $\Pr\left(\bigcap\limits_{i\in I} \overline{E_i}\right)=\prod\limits_{i\in I}\Pr(\overline{E_i})$.\\
$\Pr\left(\bigcap\limits_{i\in I} \overline{E_i}\right)=\Pr\left(\overline{\bigcup\limits_{i\in I}E_i}\right) = 1-\Pr\left(\bigcup\limits_{i\in I}E_i\right)$\\
$=1-\left(\sum\limits_{i\in I}\Pr(E_i)-\sum\limits_{i<j\in I}\Pr(E_i\cap E_j)+\cdots+(-1)^{|I|+1}\Pr\left(\bigcap\limits_{i\in I}E_i\right)\right)$\\
$=1-\sum\limits_{i\in I}\Pr(E_i)+\sum\limits_{i<j\in I}\Pr(E_i)\Pr(E_j)+\cdots+(-1)^{|I|}\prod\limits_{i\in I}\Pr(E_i)$\\
$=\prod\limits_{i\in I}(1-\Pr(E_i))=\prod\limits_{i\in I}\Pr(\overline{E_i})$. $\blacksquare$
\section*{1.21}
Suppose that a fair four-sided die is rolled. Let $X=\{1,2\}$, $y=\{1,3\}$,$Z=\{1,4\}$. Then the events are pairwise independent but not mutually independent ($1/4=\Pr(X\cap Y\cap Z) \neq \Pr(X)\Pr(Y)\Pr(Z)=1/8$.
\section*{1.22}
(a) For any $X \subset \{1,\cdots,n\}$, each element in $X$ is chosen with probability $1/2$, and each element not in $X$ is dropped with probability $1/2$.
Thus, the probability of $X$ to be generated is $1/2^{|X|}\times1/2^{n-|X|}=1/2^n$.
As there are $2^n$ possible subsets, $X$ is equally likely to be any one of the possible subsets.\\
(b) For $X\subseteq Y$, each element in $X$ must be in $Y$, which happens with probability $3/4$. Thus, $\Pr(X\subseteq Y)=(3/4)^n$.\\
For $X\cup Y = \{1,\cdots,n\}$, each element in $\{1,\cdots,n\}$ must be in at least one of two sets $X$ and $Y$, which happens with probability $3/4$. Thus, $\Pr(X\cup Y = \{1,\cdots,n\})=(3/4)^n$.
\section*{1.23}
After executing the randomized min-cut algorithm, there can be at most $\binom{n}{2}$ edges between the two vertices in the reduced graph, as $n$ vertices are assumed.
As each edge is a candidate for min-cut sets, there can be at most $\binom{n}{2}=\frac{n(n-1)}{2}$ distinct min-cut sets.
\section*{1.24}
\section*{1.25}
\end{document}
